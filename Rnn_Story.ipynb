{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\91918\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\91918\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\91918\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\91918\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\91918\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91918\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\91918\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91918\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\91918\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    LEARNING_RATE = 0.01\n",
    "    EPOCHS = 100\n",
    "    HIDDEN_DIM = 128\n",
    "    EMBEDDING_DIM = 256\n",
    "    SEQ_LENGTH = 10\n",
    "    NUM_LAYERS = 4\n",
    "    BATCH_SIZE = 64\n",
    "    UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "config = Config()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the sentence into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(sentence):\n",
    "    return sentence.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset class for text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryDataset(Dataset): \n",
    "    def __init__(self,data,seq_length):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.seq_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return(torch.tensor(self.data[idx:idx+self.seq_length]),\n",
    "               torch.tensor(self.data[idx+1:idx+self.seq_length+1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerationModel(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_dim,num_layers,model_type=\"LSTM\"):\n",
    "        super(TextGenerationModel,self).__init__()\n",
    "        self.model_type = model_type\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "\n",
    "        if model_type==\"RNN\":\n",
    "            self.rnn = nn.RNN(embedding_dim,hidden_dim,num_layers,batch_first=True)\n",
    "        elif model_type==\"LSTM\":\n",
    "            self.rnn = nn.LSTM(embedding_dim,hidden_dim,num_layers,batch_first=True)\n",
    "        elif model_type==\"GRU\":\n",
    "            self.rnn = nn.GRU(embedding_dim,hidden_dim,num_layers,batch_first=True)\n",
    "        elif model_type==\"BiLSTM\":\n",
    "            self.rnn = nn.LSTM(embedding_dim,hidden_dim,num_layers,batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type\")\n",
    "        \n",
    "        if model_type==\"BiLSTM\":\n",
    "            self.fc = nn.Linear(hidden_dim*2,vocab_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim,vocab_size)\n",
    "    \n",
    "    def forward(self,x,hidden):\n",
    "        x = self.embedding(x)\n",
    "        out,hidden = self.rnn(x,hidden)\n",
    "        out = self.fc(out)\n",
    "        return out,hidden\n",
    "    \n",
    "    def hidden_init(self,batch_size):\n",
    "        if self.model_type==\"LSTM\" or self.model_type==\"BiLSTM\":\n",
    "            return (torch.zeros(config.NUM_LAYERS,batch_size,config.HIDDEN_DIM),\n",
    "                    (torch.zeros(config.NUM_LAYERS,batch_size,config.HIDDEN_DIM)))\n",
    "        else:\n",
    "             return (torch.zeros(config.NUM_LAYERS,batch_size,config.HIDDEN_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(vocab_size,model_type=\"LSTM\"):\n",
    "    model = TextGenerationModel(vocab_size,config.EMBEDDING_DIM,config.HIDDEN_DIM,\n",
    "                                config.NUM_LAYERS,model_type=model_type)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,dataloader,epochs,lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx , (inputs,targets) in enumerate(dataloader):\n",
    "            batch_size = inputs.size(0)\n",
    "            hidden = model.hidden_init(batch_size)\n",
    "\n",
    "            hidden = tuple(h.detach() for h in hidden) if isinstance(hidden,tuple) else hidden.detach()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs,hidden = model(inputs,hidden)\n",
    "            loss = criterion(outputs.view(-1,len(vocab)),targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx%10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}],Step[{batch_idx}/{len(dataloader)}] , Loss: {loss.item():.4f}\")\n",
    "    print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,start_text,length,word2idx,idx2word):\n",
    "    model.eval()\n",
    "    tokens = tokenize_text(start_text)\n",
    "\n",
    "    input_seq = torch.tensor(\n",
    "        [word2idx.get(word,word2idx[config.UNK_TOKEN]) for word in tokens],\n",
    "        dtype = torch.long\n",
    "    ).unsqueeze(0)\n",
    "\n",
    "    hidden = model.hidden_init(1)\n",
    "\n",
    "    generate_text = start_text\n",
    "\n",
    "    for _ in range(length):\n",
    "        output,hidden = model(input_seq,hidden)\n",
    "        next_word_idx = output.argmax(dim=2)[:,-1].item()\n",
    "        next_word = idx2word[next_word_idx]\n",
    "\n",
    "        generate_text+=\" \"+next_word\n",
    "        input_seq=torch.cat([input_seq,torch.tensor([[next_word_idx]])],dim=1)[: , -config.SEQ_LENGTH:]\n",
    "        \n",
    "    return generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(story):\n",
    "    tokenized_story = tokenize_text(story)\n",
    "    vocab = sorted(set(tokenized_story))\n",
    "    word2idx = {word : i for i,word in enumerate(vocab)}\n",
    "    idx2word = {i : word for i,word in enumerate(vocab)}\n",
    "\n",
    "    # Add UNK token to vocabulary\n",
    "    if config.UNK_TOKEN not in vocab:\n",
    "        vocab.append(config.UNK_TOKEN)\n",
    "        word2idx[config.UNK_TOKEN] = len(word2idx)\n",
    "        idx2word[len (idx2word)] = config.UNK_TOKEN\n",
    "    # Convert tokenized story to indices\n",
    "    data = [word2idx[word] for word in tokenized_story]\n",
    "    # Create dataset and dataloader\n",
    "    dataset = StoryDataset (data, config.SEQ_LENGTH)\n",
    "    dataloader = DataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "    return dataloader, vocab, word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(dataloader, vocab_size, model_type):\n",
    "    model = get_model(vocab_size, model_type)\n",
    "    train_model(model, dataloader, config. EPOCHS, config.LEARNING_RATE)\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f\"text_generation_{model_type}.pth\")\n",
    "    print (f\"Model saved to text_generation_{model_type}.pth\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(vocab_size, model_type):\n",
    "    model = get_model(vocab_size, model_type)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(f\"text_generation_{model_type}.pth\"))\n",
    "        print (f\"Model loaded from text_generation_{model_type}.pth\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model file text_generation_{model_type}.pth not found. Please train the model first.\")\n",
    "        return None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100],Step[0/2] , Loss: 4.1448\n",
      "Epoch [2/100],Step[0/2] , Loss: 3.9972\n",
      "Epoch [3/100],Step[0/2] , Loss: 3.7749\n",
      "Epoch [4/100],Step[0/2] , Loss: 3.4803\n",
      "Epoch [5/100],Step[0/2] , Loss: 3.1059\n",
      "Epoch [6/100],Step[0/2] , Loss: 2.6876\n",
      "Epoch [7/100],Step[0/2] , Loss: 2.3763\n",
      "Epoch [8/100],Step[0/2] , Loss: 2.0375\n",
      "Epoch [9/100],Step[0/2] , Loss: 1.8265\n",
      "Epoch [10/100],Step[0/2] , Loss: 1.6634\n",
      "Epoch [11/100],Step[0/2] , Loss: 1.5046\n",
      "Epoch [12/100],Step[0/2] , Loss: 1.3694\n",
      "Epoch [13/100],Step[0/2] , Loss: 1.2067\n",
      "Epoch [14/100],Step[0/2] , Loss: 1.1198\n",
      "Epoch [15/100],Step[0/2] , Loss: 1.0832\n",
      "Epoch [16/100],Step[0/2] , Loss: 0.9560\n",
      "Epoch [17/100],Step[0/2] , Loss: 0.8398\n",
      "Epoch [18/100],Step[0/2] , Loss: 0.7577\n",
      "Epoch [19/100],Step[0/2] , Loss: 0.6752\n",
      "Epoch [20/100],Step[0/2] , Loss: 0.6039\n",
      "Epoch [21/100],Step[0/2] , Loss: 0.5342\n",
      "Epoch [22/100],Step[0/2] , Loss: 0.4724\n",
      "Epoch [23/100],Step[0/2] , Loss: 0.4282\n",
      "Epoch [24/100],Step[0/2] , Loss: 0.3741\n",
      "Epoch [25/100],Step[0/2] , Loss: 0.3408\n",
      "Epoch [26/100],Step[0/2] , Loss: 0.3204\n",
      "Epoch [27/100],Step[0/2] , Loss: 0.3184\n",
      "Epoch [28/100],Step[0/2] , Loss: 0.2229\n",
      "Epoch [29/100],Step[0/2] , Loss: 0.2173\n",
      "Epoch [30/100],Step[0/2] , Loss: 0.2057\n",
      "Epoch [31/100],Step[0/2] , Loss: 0.1804\n",
      "Epoch [32/100],Step[0/2] , Loss: 0.1862\n",
      "Epoch [33/100],Step[0/2] , Loss: 0.1585\n",
      "Epoch [34/100],Step[0/2] , Loss: 0.1442\n",
      "Epoch [35/100],Step[0/2] , Loss: 0.1284\n",
      "Epoch [36/100],Step[0/2] , Loss: 0.1169\n",
      "Epoch [37/100],Step[0/2] , Loss: 0.1130\n",
      "Epoch [38/100],Step[0/2] , Loss: 0.1131\n",
      "Epoch [39/100],Step[0/2] , Loss: 0.1072\n",
      "Epoch [40/100],Step[0/2] , Loss: 0.0968\n",
      "Epoch [41/100],Step[0/2] , Loss: 0.0956\n",
      "Epoch [42/100],Step[0/2] , Loss: 0.0907\n",
      "Epoch [43/100],Step[0/2] , Loss: 0.0863\n",
      "Epoch [44/100],Step[0/2] , Loss: 0.0775\n",
      "Epoch [45/100],Step[0/2] , Loss: 0.0833\n",
      "Epoch [46/100],Step[0/2] , Loss: 0.0694\n",
      "Epoch [47/100],Step[0/2] , Loss: 0.0732\n",
      "Epoch [48/100],Step[0/2] , Loss: 0.0743\n",
      "Epoch [49/100],Step[0/2] , Loss: 0.0673\n",
      "Epoch [50/100],Step[0/2] , Loss: 0.0693\n",
      "Epoch [51/100],Step[0/2] , Loss: 0.0675\n",
      "Epoch [52/100],Step[0/2] , Loss: 0.0664\n",
      "Epoch [53/100],Step[0/2] , Loss: 0.0636\n",
      "Epoch [54/100],Step[0/2] , Loss: 0.0646\n",
      "Epoch [55/100],Step[0/2] , Loss: 0.0568\n",
      "Epoch [56/100],Step[0/2] , Loss: 0.0595\n",
      "Epoch [57/100],Step[0/2] , Loss: 0.0634\n",
      "Epoch [58/100],Step[0/2] , Loss: 0.0611\n",
      "Epoch [59/100],Step[0/2] , Loss: 0.0638\n",
      "Epoch [60/100],Step[0/2] , Loss: 0.0638\n",
      "Epoch [61/100],Step[0/2] , Loss: 0.0588\n",
      "Epoch [62/100],Step[0/2] , Loss: 0.0568\n",
      "Epoch [63/100],Step[0/2] , Loss: 0.0635\n",
      "Epoch [64/100],Step[0/2] , Loss: 0.0561\n",
      "Epoch [65/100],Step[0/2] , Loss: 0.0595\n",
      "Epoch [66/100],Step[0/2] , Loss: 0.0599\n",
      "Epoch [67/100],Step[0/2] , Loss: 0.0603\n",
      "Epoch [68/100],Step[0/2] , Loss: 0.0618\n",
      "Epoch [69/100],Step[0/2] , Loss: 0.0576\n",
      "Epoch [70/100],Step[0/2] , Loss: 0.0555\n",
      "Epoch [71/100],Step[0/2] , Loss: 0.0501\n",
      "Epoch [72/100],Step[0/2] , Loss: 0.0542\n",
      "Epoch [73/100],Step[0/2] , Loss: 0.0499\n",
      "Epoch [74/100],Step[0/2] , Loss: 0.0527\n",
      "Epoch [75/100],Step[0/2] , Loss: 0.0546\n",
      "Epoch [76/100],Step[0/2] , Loss: 0.0591\n",
      "Epoch [77/100],Step[0/2] , Loss: 0.0542\n",
      "Epoch [78/100],Step[0/2] , Loss: 0.0572\n",
      "Epoch [79/100],Step[0/2] , Loss: 0.0553\n",
      "Epoch [80/100],Step[0/2] , Loss: 0.0544\n",
      "Epoch [81/100],Step[0/2] , Loss: 0.0543\n",
      "Epoch [82/100],Step[0/2] , Loss: 0.0483\n",
      "Epoch [83/100],Step[0/2] , Loss: 0.0502\n",
      "Epoch [84/100],Step[0/2] , Loss: 0.0521\n",
      "Epoch [85/100],Step[0/2] , Loss: 0.0500\n",
      "Epoch [86/100],Step[0/2] , Loss: 0.0503\n",
      "Epoch [87/100],Step[0/2] , Loss: 0.0523\n",
      "Epoch [88/100],Step[0/2] , Loss: 0.0505\n",
      "Epoch [89/100],Step[0/2] , Loss: 0.0559\n",
      "Epoch [90/100],Step[0/2] , Loss: 0.0574\n",
      "Epoch [91/100],Step[0/2] , Loss: 0.0598\n",
      "Epoch [92/100],Step[0/2] , Loss: 0.0580\n",
      "Epoch [93/100],Step[0/2] , Loss: 0.0557\n",
      "Epoch [94/100],Step[0/2] , Loss: 0.0523\n",
      "Epoch [95/100],Step[0/2] , Loss: 0.0522\n",
      "Epoch [96/100],Step[0/2] , Loss: 0.0511\n",
      "Epoch [97/100],Step[0/2] , Loss: 0.0506\n",
      "Epoch [98/100],Step[0/2] , Loss: 0.0508\n",
      "Epoch [99/100],Step[0/2] , Loss: 0.0494\n",
      "Epoch [100/100],Step[0/2] , Loss: 0.0459\n",
      "Training completed\n",
      "Model saved to text_generation_LSTM.pth\n",
      "Generated Story: \n",
      " One day a girl named Saara lily discovered a mysterious cave hidden in the forest. she was curious and decided to explore. inside the cave, she found glowing crystals and strange markings on the walls. as she ventured deeper, she realized she was not alone. by the villagers lived in harmony with nature. they grew crops,\n"
     ]
    }
   ],
   "source": [
    "def run_inference (model, start_text, length, word2idx, idx2word):\n",
    "    generated_story = generate_text(model, start_text, length, word2idx, idx2word)\n",
    "    print(\"Generated Story: \\n\", generated_story)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    story = \"\"\"\n",
    "    Once upon a time, in a land far away, there was a peaceful village surrounded by mountains.\n",
    "    The villagers lived in harmony with nature. They grew crops, raised animals, and lived a simple but happy life.\n",
    "    One day, a young girl named Lily discovered a mysterious cave hidden in the forest. She was curious and decided to explore.\n",
    "    Inside the cave, she found glowing crystals and strange markings on the walls.\n",
    "    As she ventured deeper, she realized she was not alone. \"\"\"\n",
    "\n",
    "    dataloader, vocab, word2idx, idx2word = prepare_dataset (story)\n",
    "    model_type = \"LSTM\"\n",
    "    model = train_and_save_model(dataloader, len (vocab), model_type)\n",
    "\n",
    "    start_text = \"One day a girl named Saara\"\n",
    "    run_inference(model, start_text, length=50, word2idx=word2idx, idx2word=idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
